{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check columns in thresholds_df\n",
        "print(\"Columns in thresholds_df:\", thresholds_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhh7yeiw9w7_",
        "outputId": "c723f1ee-0acf-411e-e8f8-a6e8cedab69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in thresholds_df: ['District Name', 'District Population', 'Residential Energy Consumption (MU/year)', 'Residential Energy Consumption (kWh/year)', 'Per Capita Energy Consumption (kWh/year)', 'Source of Energy', 'Carbon Emission Factor (kg CO2/kWh)', 'Carbon Emissions (kg CO2/year)', 'Carbon Emissions (tons CO2/year)', 'Population Density (per sq. km)', 'Category', 'Sub-District', 'Sub-District Population', 'Emission Limit (kg CO2/year)', 'Emission Limit (kg CO2/month)', 'Low_Threshold', 'Moderate_Threshold', 'High_Threshold']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the datasets\n",
        "household_df = pd.read_csv('/content/10000_balanced_household_dataset.csv')  # Path to household dataset\n",
        "thresholds_df = pd.read_csv('/content/updated_REM_dataset_with_thresholds (1).csv')  # Path to thresholds dataset\n",
        "\n",
        "# Conversion factor from kWh to kg CO₂\n",
        "conversion_factor = 0.75284\n",
        "\n",
        "# Step 2: Calculate carbon emissions for each appliance in the household dataset\n",
        "household_df['Carbon_Emission_per_Appliance (kg CO₂)'] = (\n",
        "    household_df['Energy Consumption (kWh)'] * household_df['Monthly Usage Hours'] * conversion_factor\n",
        ")\n",
        "\n",
        "# Step 3: Sum emissions for all appliances in each household\n",
        "household_carbon_emissions = household_df.groupby('Household ID')['Carbon_Emission_per_Appliance (kg CO₂)'].sum().reset_index()\n",
        "household_carbon_emissions.rename(columns={'Carbon_Emission_per_Appliance (kg CO₂)': 'Total_Carbon_Emission (kg CO₂)'}, inplace=True)\n",
        "\n",
        "# Step 4: Merge household information (Sub-District and District) to get regional thresholds\n",
        "household_info = household_df[['Household ID', 'Sub-District', 'District Name']].drop_duplicates()\n",
        "household_carbon_emissions = household_carbon_emissions.merge(household_info, on='Household ID', how='left')\n",
        "\n",
        "# Ensure that the thresholds dataset has necessary columns\n",
        "required_columns = ['Low_Threshold', 'Moderate_Threshold', 'High_Threshold', 'Sub-District', 'District Name']\n",
        "if not all(col in thresholds_df.columns for col in required_columns):\n",
        "    raise ValueError(\"Thresholds dataset is missing one or more required columns.\")\n",
        "\n",
        "# Step 5: Merge with thresholds dataset\n",
        "combined_df = household_carbon_emissions.merge(thresholds_df, on=['Sub-District', 'District Name'], how='left')\n",
        "\n",
        "# Check for missing values in the threshold columns after merging\n",
        "if combined_df[['Low_Threshold', 'Moderate_Threshold', 'High_Threshold']].isnull().any().any():\n",
        "    raise ValueError(\"Missing threshold values after merging. Ensure all sub-districts match between datasets.\")\n",
        "\n",
        "# Step 6: Categorize emissions based on thresholds\n",
        "def categorize_emission(row):\n",
        "    if row['Total_Carbon_Emission (kg CO₂)'] <= row['Low_Threshold']:\n",
        "        return 0  # Low\n",
        "    elif row['Total_Carbon_Emission (kg CO₂)'] >= row['High_Threshold']:\n",
        "        return 2  # High\n",
        "    else:\n",
        "        return 1  # Moderate\n",
        "\n",
        "combined_df['Emission_Category'] = combined_df.apply(categorize_emission, axis=1)\n",
        "\n",
        "# Check the final DataFrame\n",
        "print(combined_df[['Household ID', 'Total_Carbon_Emission (kg CO₂)', 'Low_Threshold', 'Moderate_Threshold', 'High_Threshold', 'Emission_Category']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmFsu4YMzRel",
        "outputId": "802a307a-7f56-4380-c531-5935cb2ad8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Household ID  Total_Carbon_Emission (kg CO₂)  Low_Threshold  \\\n",
            "0             1                      218.270901     808.390279   \n",
            "1             2                      348.196028     755.559324   \n",
            "2             3                      396.761737     464.211075   \n",
            "3             4                      230.700290     541.384772   \n",
            "4             5                      365.895297     269.657924   \n",
            "\n",
            "   Moderate_Threshold  High_Threshold  Emission_Category  \n",
            "0         1455.102502     1616.780558                  0  \n",
            "1         1360.006782     1511.118647                  0  \n",
            "2          835.579935      928.422150                  0  \n",
            "3          974.492589     1082.769543                  0  \n",
            "4          485.384263      539.315848                  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Drop unnecessary columns and prepare features (X) and target (y)\n",
        "X = combined_df.drop(['Household ID', 'Emission_Category', 'Sub-District', 'District Name', 'Low_Threshold', 'Moderate_Threshold', 'High_Threshold'], axis=1)\n",
        "y = combined_df['Emission_Category']\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "z8HhN9vNzRbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Build the MLP model\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "mlp_model.add(Dropout(0.2))\n",
        "mlp_model.add(Dense(64, activation='relu'))\n",
        "mlp_model.add(Dropout(0.2))\n",
        "mlp_model.add(Dense(32, activation='relu'))\n",
        "mlp_model.add(Dense(3, activation='softmax'))  # 3 classes: low, moderate, high\n",
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "mlp_history = mlp_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYC9XCeBzRY4",
        "outputId": "befe1a73-79d5-4fe6-ee3f-949d163b13be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.5303 - val_accuracy: 0.9425 - val_loss: 0.1859\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1910 - val_accuracy: 0.9619 - val_loss: 0.1077\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1279 - val_accuracy: 0.9725 - val_loss: 0.0803\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1050 - val_accuracy: 0.9756 - val_loss: 0.0680\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0927 - val_accuracy: 0.9769 - val_loss: 0.0636\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0849 - val_accuracy: 0.9725 - val_loss: 0.0635\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0822 - val_accuracy: 0.9806 - val_loss: 0.0545\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0804 - val_accuracy: 0.9781 - val_loss: 0.0665\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.0774 - val_accuracy: 0.9731 - val_loss: 0.0570\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0855 - val_accuracy: 0.9806 - val_loss: 0.0568\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0686 - val_accuracy: 0.9787 - val_loss: 0.0562\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0690 - val_accuracy: 0.9787 - val_loss: 0.0509\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0722 - val_accuracy: 0.9812 - val_loss: 0.0464\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0674 - val_accuracy: 0.9800 - val_loss: 0.0490\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0678 - val_accuracy: 0.9800 - val_loss: 0.0525\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0701 - val_accuracy: 0.9787 - val_loss: 0.0472\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0655 - val_accuracy: 0.9812 - val_loss: 0.0480\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0635 - val_accuracy: 0.9750 - val_loss: 0.0560\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0752 - val_accuracy: 0.9812 - val_loss: 0.0464\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0648 - val_accuracy: 0.9812 - val_loss: 0.0488\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0598 - val_accuracy: 0.9806 - val_loss: 0.0482\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0578 - val_accuracy: 0.9831 - val_loss: 0.0409\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.0692 - val_accuracy: 0.9831 - val_loss: 0.0427\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0614 - val_accuracy: 0.9806 - val_loss: 0.0478\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0585 - val_accuracy: 0.9800 - val_loss: 0.0488\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0582 - val_accuracy: 0.9825 - val_loss: 0.0454\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0550 - val_accuracy: 0.9762 - val_loss: 0.0494\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0640 - val_accuracy: 0.9856 - val_loss: 0.0388\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0520 - val_accuracy: 0.9812 - val_loss: 0.0407\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0544 - val_accuracy: 0.9856 - val_loss: 0.0411\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0530 - val_accuracy: 0.9806 - val_loss: 0.0430\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0582 - val_accuracy: 0.9800 - val_loss: 0.0431\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0660 - val_accuracy: 0.9819 - val_loss: 0.0439\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0608 - val_accuracy: 0.9812 - val_loss: 0.0416\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0524 - val_accuracy: 0.9781 - val_loss: 0.0636\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0607 - val_accuracy: 0.9812 - val_loss: 0.0384\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0651 - val_accuracy: 0.9744 - val_loss: 0.0617\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0595 - val_accuracy: 0.9794 - val_loss: 0.0416\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0515 - val_accuracy: 0.9837 - val_loss: 0.0424\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0564 - val_accuracy: 0.9800 - val_loss: 0.0375\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0528 - val_accuracy: 0.9787 - val_loss: 0.0419\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0568 - val_accuracy: 0.9769 - val_loss: 0.0529\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0565 - val_accuracy: 0.9856 - val_loss: 0.0387\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0526 - val_accuracy: 0.9800 - val_loss: 0.0523\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0501 - val_accuracy: 0.9875 - val_loss: 0.0412\n",
            "Epoch 46/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0569 - val_accuracy: 0.9781 - val_loss: 0.0497\n",
            "Epoch 47/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0496 - val_accuracy: 0.9844 - val_loss: 0.0387\n",
            "Epoch 48/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0432 - val_accuracy: 0.9744 - val_loss: 0.0638\n",
            "Epoch 49/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0508 - val_accuracy: 0.9800 - val_loss: 0.0457\n",
            "Epoch 50/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0513 - val_accuracy: 0.9850 - val_loss: 0.0402\n",
            "Epoch 51/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0475 - val_accuracy: 0.9831 - val_loss: 0.0338\n",
            "Epoch 52/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0482 - val_accuracy: 0.9794 - val_loss: 0.0471\n",
            "Epoch 53/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0576 - val_accuracy: 0.9787 - val_loss: 0.0407\n",
            "Epoch 54/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0484 - val_accuracy: 0.9831 - val_loss: 0.0456\n",
            "Epoch 55/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0493 - val_accuracy: 0.9844 - val_loss: 0.0395\n",
            "Epoch 56/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0435 - val_accuracy: 0.9825 - val_loss: 0.0364\n",
            "Epoch 57/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0527 - val_accuracy: 0.9819 - val_loss: 0.0385\n",
            "Epoch 58/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0518 - val_accuracy: 0.9825 - val_loss: 0.0373\n",
            "Epoch 59/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0470 - val_accuracy: 0.9825 - val_loss: 0.0408\n",
            "Epoch 60/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0468 - val_accuracy: 0.9856 - val_loss: 0.0352\n",
            "Epoch 61/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0491 - val_accuracy: 0.9850 - val_loss: 0.0381\n",
            "Epoch 62/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0376 - val_accuracy: 0.9825 - val_loss: 0.0342\n",
            "Epoch 63/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0494 - val_accuracy: 0.9819 - val_loss: 0.0452\n",
            "Epoch 64/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0525 - val_accuracy: 0.9856 - val_loss: 0.0345\n",
            "Epoch 65/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0485 - val_accuracy: 0.9831 - val_loss: 0.0469\n",
            "Epoch 66/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0483 - val_accuracy: 0.9825 - val_loss: 0.0346\n",
            "Epoch 67/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0457 - val_accuracy: 0.9800 - val_loss: 0.0509\n",
            "Epoch 68/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0446 - val_accuracy: 0.9812 - val_loss: 0.0425\n",
            "Epoch 69/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0497 - val_accuracy: 0.9900 - val_loss: 0.0282\n",
            "Epoch 70/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0514 - val_accuracy: 0.9875 - val_loss: 0.0302\n",
            "Epoch 71/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0517 - val_accuracy: 0.9875 - val_loss: 0.0318\n",
            "Epoch 72/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0430 - val_accuracy: 0.9862 - val_loss: 0.0351\n",
            "Epoch 73/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0475 - val_accuracy: 0.9819 - val_loss: 0.0333\n",
            "Epoch 74/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0478 - val_accuracy: 0.9831 - val_loss: 0.0322\n",
            "Epoch 75/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0520 - val_accuracy: 0.9844 - val_loss: 0.0356\n",
            "Epoch 76/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0435 - val_accuracy: 0.9856 - val_loss: 0.0331\n",
            "Epoch 77/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0445 - val_accuracy: 0.9831 - val_loss: 0.0367\n",
            "Epoch 78/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0483 - val_accuracy: 0.9831 - val_loss: 0.0383\n",
            "Epoch 79/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0481 - val_accuracy: 0.9881 - val_loss: 0.0352\n",
            "Epoch 80/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0551 - val_accuracy: 0.9881 - val_loss: 0.0318\n",
            "Epoch 81/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0434 - val_accuracy: 0.9819 - val_loss: 0.0436\n",
            "Epoch 82/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0470 - val_accuracy: 0.9894 - val_loss: 0.0342\n",
            "Epoch 83/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0446 - val_accuracy: 0.9887 - val_loss: 0.0286\n",
            "Epoch 84/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0391 - val_accuracy: 0.9831 - val_loss: 0.0342\n",
            "Epoch 85/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0437 - val_accuracy: 0.9819 - val_loss: 0.0427\n",
            "Epoch 86/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0427 - val_accuracy: 0.9881 - val_loss: 0.0323\n",
            "Epoch 87/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0435 - val_accuracy: 0.9831 - val_loss: 0.0387\n",
            "Epoch 88/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0459 - val_accuracy: 0.9912 - val_loss: 0.0270\n",
            "Epoch 89/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0496 - val_accuracy: 0.9862 - val_loss: 0.0402\n",
            "Epoch 90/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0428 - val_accuracy: 0.9769 - val_loss: 0.0647\n",
            "Epoch 91/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0568 - val_accuracy: 0.9850 - val_loss: 0.0374\n",
            "Epoch 92/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0494 - val_accuracy: 0.9831 - val_loss: 0.0420\n",
            "Epoch 93/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0417 - val_accuracy: 0.9837 - val_loss: 0.0387\n",
            "Epoch 94/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0477 - val_accuracy: 0.9825 - val_loss: 0.0438\n",
            "Epoch 95/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0330 - val_accuracy: 0.9837 - val_loss: 0.0446\n",
            "Epoch 96/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0524 - val_accuracy: 0.9856 - val_loss: 0.0324\n",
            "Epoch 97/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0463 - val_accuracy: 0.9812 - val_loss: 0.0466\n",
            "Epoch 98/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0431 - val_accuracy: 0.9819 - val_loss: 0.0410\n",
            "Epoch 99/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0477 - val_accuracy: 0.9844 - val_loss: 0.0386\n",
            "Epoch 100/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0482 - val_accuracy: 0.9762 - val_loss: 0.0499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_train_predictions = mlp_model.predict(X_train)\n",
        "mlp_test_predictions = mlp_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels for use in XGBoost\n",
        "mlp_train_predictions = np.argmax(mlp_train_predictions, axis=1)\n",
        "mlp_test_predictions = np.argmax(mlp_test_predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcf01XnbTsBr",
        "outputId": "b90dc7e5-5e3f-410b-afe9-d01cf04adf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_combined = np.hstack((X_train, mlp_train_predictions.reshape(-1, 1)))  # Add MLP predictions as features\n",
        "X_test_combined = np.hstack((X_test, mlp_test_predictions.reshape(-1, 1)))  # Add MLP predictions as features"
      ],
      "metadata": {
        "id": "gOn0v2upTvAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Get MLP predictions\n",
        "mlp_train_predictions = mlp_model.predict(X_train)\n",
        "mlp_test_predictions = mlp_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels for use in XGBoost\n",
        "mlp_train_features = np.hstack((X_train, mlp_train_predictions))\n",
        "mlp_test_features = np.hstack((X_test, mlp_test_predictions))\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_model.fit(mlp_train_features, y_train)\n",
        "# Make predictions with XGBoost\n",
        "xgb_predictions = xgb_model.predict(mlp_test_features)\n",
        "\n",
        "# Evaluate the combined model\n",
        "combined_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "print(f\"Combined Model Accuracy: {combined_accuracy:.4f}\")\n",
        "print(classification_report(y_test, xgb_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L01yElqWzRTZ",
        "outputId": "2d6595b5-a51b-4e8e-9e56-8fad247347a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:13:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Model Accuracy: 0.9960\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       368\n",
            "           1       0.97      0.96      0.96       112\n",
            "           2       1.00      1.00      1.00      1520\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.98      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Build the MLP model\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "mlp_model.add(Dropout(0.2))\n",
        "mlp_model.add(Dense(64, activation='relu'))\n",
        "mlp_model.add(Dropout(0.2))\n",
        "mlp_model.add(Dense(32, activation='relu'))\n",
        "mlp_model.add(Dense(3, activation='softmax'))  # 3 classes: low, moderate, high\n",
        "\n",
        "# Compile the MLP model\n",
        "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the MLP model\n",
        "mlp_history = mlp_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Get MLP predictions\n",
        "mlp_train_predictions = mlp_model.predict(X_train)\n",
        "mlp_test_predictions = mlp_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "mlp_train_predictions = np.argmax(mlp_train_predictions, axis=1)\n",
        "mlp_test_predictions = np.argmax(mlp_test_predictions, axis=1)\n",
        "\n",
        "# Combine MLP predictions with the original features (for both train and test sets)\n",
        "X_train_combined = np.hstack((X_train, mlp_train_predictions.reshape(-1, 1)))  # Add MLP predictions as features\n",
        "X_test_combined = np.hstack((X_test, mlp_test_predictions.reshape(-1, 1)))  # Add MLP predictions as features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JgAV73iXJF",
        "outputId": "56989391-3a76-4e8d-b574-b03bded3a416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5518 - val_accuracy: 0.9531 - val_loss: 0.1630\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.1793 - val_accuracy: 0.9681 - val_loss: 0.0854\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1195 - val_accuracy: 0.9669 - val_loss: 0.0808\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.0979 - val_accuracy: 0.9737 - val_loss: 0.0693\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.0963 - val_accuracy: 0.9756 - val_loss: 0.0755\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0914 - val_accuracy: 0.9725 - val_loss: 0.0702\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0803 - val_accuracy: 0.9819 - val_loss: 0.0551\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0799 - val_accuracy: 0.9725 - val_loss: 0.0644\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0814 - val_accuracy: 0.9769 - val_loss: 0.0592\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.0744 - val_accuracy: 0.9806 - val_loss: 0.0490\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0762 - val_accuracy: 0.9825 - val_loss: 0.0512\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0695 - val_accuracy: 0.9744 - val_loss: 0.0671\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0823 - val_accuracy: 0.9706 - val_loss: 0.0688\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0686 - val_accuracy: 0.9756 - val_loss: 0.0633\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0659 - val_accuracy: 0.9781 - val_loss: 0.0506\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0688 - val_accuracy: 0.9769 - val_loss: 0.0589\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0710 - val_accuracy: 0.9787 - val_loss: 0.0536\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0674 - val_accuracy: 0.9806 - val_loss: 0.0554\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0779 - val_accuracy: 0.9769 - val_loss: 0.0612\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.0622 - val_accuracy: 0.9769 - val_loss: 0.0573\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.0697 - val_accuracy: 0.9787 - val_loss: 0.0534\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0597 - val_accuracy: 0.9800 - val_loss: 0.0479\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0603 - val_accuracy: 0.9812 - val_loss: 0.0537\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0603 - val_accuracy: 0.9800 - val_loss: 0.0463\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0556 - val_accuracy: 0.9794 - val_loss: 0.0479\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0577 - val_accuracy: 0.9787 - val_loss: 0.0566\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0583 - val_accuracy: 0.9794 - val_loss: 0.0476\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0565 - val_accuracy: 0.9769 - val_loss: 0.0631\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0561 - val_accuracy: 0.9800 - val_loss: 0.0439\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0580 - val_accuracy: 0.9856 - val_loss: 0.0422\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0579 - val_accuracy: 0.9800 - val_loss: 0.0461\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0524 - val_accuracy: 0.9794 - val_loss: 0.0475\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0531 - val_accuracy: 0.9837 - val_loss: 0.0426\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0630 - val_accuracy: 0.9812 - val_loss: 0.0413\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0603 - val_accuracy: 0.9800 - val_loss: 0.0446\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0622 - val_accuracy: 0.9794 - val_loss: 0.0439\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0537 - val_accuracy: 0.9844 - val_loss: 0.0403\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0573 - val_accuracy: 0.9856 - val_loss: 0.0405\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0548 - val_accuracy: 0.9862 - val_loss: 0.0435\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0594 - val_accuracy: 0.9844 - val_loss: 0.0454\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0571 - val_accuracy: 0.9850 - val_loss: 0.0377\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0571 - val_accuracy: 0.9837 - val_loss: 0.0414\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0532 - val_accuracy: 0.9800 - val_loss: 0.0455\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0490 - val_accuracy: 0.9862 - val_loss: 0.0448\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0520 - val_accuracy: 0.9769 - val_loss: 0.0611\n",
            "Epoch 46/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0571 - val_accuracy: 0.9812 - val_loss: 0.0488\n",
            "Epoch 47/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0635 - val_accuracy: 0.9812 - val_loss: 0.0444\n",
            "Epoch 48/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0518 - val_accuracy: 0.9850 - val_loss: 0.0410\n",
            "Epoch 49/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0495 - val_accuracy: 0.9812 - val_loss: 0.0448\n",
            "Epoch 50/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0486 - val_accuracy: 0.9744 - val_loss: 0.0667\n",
            "Epoch 51/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0574 - val_accuracy: 0.9862 - val_loss: 0.0380\n",
            "Epoch 52/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0526 - val_accuracy: 0.9856 - val_loss: 0.0387\n",
            "Epoch 53/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0526 - val_accuracy: 0.9856 - val_loss: 0.0357\n",
            "Epoch 54/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0524 - val_accuracy: 0.9812 - val_loss: 0.0423\n",
            "Epoch 55/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0467 - val_accuracy: 0.9794 - val_loss: 0.0476\n",
            "Epoch 56/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0580 - val_accuracy: 0.9837 - val_loss: 0.0436\n",
            "Epoch 57/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0465 - val_accuracy: 0.9875 - val_loss: 0.0412\n",
            "Epoch 58/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0484 - val_accuracy: 0.9781 - val_loss: 0.0426\n",
            "Epoch 59/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0474 - val_accuracy: 0.9862 - val_loss: 0.0381\n",
            "Epoch 60/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0474 - val_accuracy: 0.9856 - val_loss: 0.0375\n",
            "Epoch 61/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0569 - val_accuracy: 0.9869 - val_loss: 0.0373\n",
            "Epoch 62/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0569 - val_accuracy: 0.9856 - val_loss: 0.0384\n",
            "Epoch 63/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0487 - val_accuracy: 0.9787 - val_loss: 0.0421\n",
            "Epoch 64/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0538 - val_accuracy: 0.9856 - val_loss: 0.0414\n",
            "Epoch 65/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0424 - val_accuracy: 0.9831 - val_loss: 0.0419\n",
            "Epoch 66/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0517 - val_accuracy: 0.9844 - val_loss: 0.0384\n",
            "Epoch 67/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0496 - val_accuracy: 0.9850 - val_loss: 0.0362\n",
            "Epoch 68/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0393 - val_accuracy: 0.9825 - val_loss: 0.0446\n",
            "Epoch 69/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0446 - val_accuracy: 0.9825 - val_loss: 0.0375\n",
            "Epoch 70/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0473 - val_accuracy: 0.9812 - val_loss: 0.0485\n",
            "Epoch 71/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0501 - val_accuracy: 0.9781 - val_loss: 0.0470\n",
            "Epoch 72/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0504 - val_accuracy: 0.9850 - val_loss: 0.0357\n",
            "Epoch 73/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0488 - val_accuracy: 0.9850 - val_loss: 0.0362\n",
            "Epoch 74/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0450 - val_accuracy: 0.9819 - val_loss: 0.0457\n",
            "Epoch 75/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0494 - val_accuracy: 0.9881 - val_loss: 0.0325\n",
            "Epoch 76/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0455 - val_accuracy: 0.9844 - val_loss: 0.0447\n",
            "Epoch 77/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0507 - val_accuracy: 0.9875 - val_loss: 0.0311\n",
            "Epoch 78/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0479 - val_accuracy: 0.9825 - val_loss: 0.0351\n",
            "Epoch 79/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0474 - val_accuracy: 0.9837 - val_loss: 0.0384\n",
            "Epoch 80/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0464 - val_accuracy: 0.9862 - val_loss: 0.0362\n",
            "Epoch 81/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0414 - val_accuracy: 0.9831 - val_loss: 0.0400\n",
            "Epoch 82/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0451 - val_accuracy: 0.9862 - val_loss: 0.0439\n",
            "Epoch 83/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0483 - val_accuracy: 0.9819 - val_loss: 0.0326\n",
            "Epoch 84/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0486 - val_accuracy: 0.9831 - val_loss: 0.0399\n",
            "Epoch 85/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0449 - val_accuracy: 0.9875 - val_loss: 0.0330\n",
            "Epoch 86/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0391 - val_accuracy: 0.9806 - val_loss: 0.0471\n",
            "Epoch 87/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0480 - val_accuracy: 0.9787 - val_loss: 0.0536\n",
            "Epoch 88/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0465 - val_accuracy: 0.9875 - val_loss: 0.0311\n",
            "Epoch 89/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0412 - val_accuracy: 0.9850 - val_loss: 0.0316\n",
            "Epoch 90/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0436 - val_accuracy: 0.9781 - val_loss: 0.0497\n",
            "Epoch 91/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0482 - val_accuracy: 0.9719 - val_loss: 0.0613\n",
            "Epoch 92/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0560 - val_accuracy: 0.9875 - val_loss: 0.0296\n",
            "Epoch 93/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0437 - val_accuracy: 0.9831 - val_loss: 0.0406\n",
            "Epoch 94/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0441 - val_accuracy: 0.9819 - val_loss: 0.0396\n",
            "Epoch 95/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0536 - val_accuracy: 0.9850 - val_loss: 0.0311\n",
            "Epoch 96/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0448 - val_accuracy: 0.9762 - val_loss: 0.0454\n",
            "Epoch 97/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0461 - val_accuracy: 0.9819 - val_loss: 0.0462\n",
            "Epoch 98/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0451 - val_accuracy: 0.9862 - val_loss: 0.0316\n",
            "Epoch 99/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0480 - val_accuracy: 0.9850 - val_loss: 0.0371\n",
            "Epoch 100/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0432 - val_accuracy: 0.9887 - val_loss: 0.0349\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the XGBoost model on the combined features\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train_combined, y_train)\n",
        "\n",
        "# Make predictions with the XGBoost model on the combined test set\n",
        "xgb_predictions = xgb_model.predict(X_test_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB5uhZ5SjARn",
        "outputId": "267e2888-26c4-455b-a49c-fa3aa74c0781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:14:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the combined model accuracy\n",
        "combined_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "print(f\"Combined Model Accuracy: {combined_accuracy:.4f}\")\n",
        "print(classification_report(y_test, xgb_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4RNC9WjExk",
        "outputId": "7fb7a8e6-ea86-48e5-af1b-ba48b19be1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Model Accuracy: 0.9950\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       368\n",
            "           1       0.96      0.96      0.96       112\n",
            "           2       1.00      1.00      1.00      1520\n",
            "\n",
            "    accuracy                           0.99      2000\n",
            "   macro avg       0.98      0.98      0.98      2000\n",
            "weighted avg       0.99      0.99      0.99      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the MLP model\n",
        "joblib.dump(mlp_model, '/content/mlp_model.pkl')\n",
        "\n",
        "# Save the XGBoost model\n",
        "joblib.dump(xgb_model, '/content/combined_xgb_model.pkl')\n",
        "\n",
        "print(\"Models saved successfully!\")\n",
        "\n",
        "# Provide download links for the models\n",
        "from google.colab import files\n",
        "files.download('/content/mlp_model.pkl')  # Download MLP model\n",
        "files.download('/content/combined_xgb_model.pkl')  # Download XGBoost model"
      ],
      "metadata": {
        "id": "yDegIuDYjJsR",
        "outputId": "794a11e8-b82e-4f25-b6ca-6a3195100ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b88f1ed8-f758-462f-ab10-130ae8be22d1\", \"mlp_model.pkl\", 178248)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c8882592-d156-45f5-ab32-e69bd6b96059\", \"combined_xgb_model.pkl\", 383724)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}